{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import product\n",
    "from pprint import pprint\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary code for the #papername\n",
    "\n",
    "## Data generators\n",
    "\n",
    "The first part of this notebook contains code for test set generation.\n",
    "\n",
    "* **First-last harmony** is a harmony where the first and the last elements of the string are vowels, and they need to agree. For example, `axoxoa` is a good word, while `axaxao` is not.\n",
    "* **Double harmony** is when a vowel harmony and a consonant harmony co-occur within the same language. For example, `apapp`, `abbap` and `popooo` are good, while `apabo` and `appoppp` are not.\n",
    "* **One or two locally-dependent simultaneous assimilations** where the trigger for a long-distance assimilation depends on a local context. For example, `e` immediately before `x` prohibits `a` anywhere further after `e` in the string. Then `eaaxaae` and `axaexeeexx` are good, while `exxae` is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First-last harmony\n",
    "The first and the last elements of the string are vowels, and they need to agree. For example, `axoxoa` is a good word, while `axaxao` is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_last_generate(n = 10, length = 10, grammatical = True, \n",
    "                        vowels = None, transparent = None):\n",
    "    \"\"\" Generates a collection words following the rule of first-last harmony.\n",
    "    \n",
    "    * n (int): number of strings that need to be generated;\n",
    "    * length (int): length of every one of the generated strings;\n",
    "    * grammatical (bool): if set to True, the correctly harmonizing\n",
    "                          forms are generated, and if set to False,\n",
    "                          the disharmonic forms are produced;\n",
    "    * vowels (list): list of vowels among which the first-last\n",
    "                     agreement is established;\n",
    "    * transparent (list): list of irrelevant elements.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialization and sanity check for the list of vowels\n",
    "    if vowels is None:\n",
    "        vowels = [\"a\", \"o\"]\n",
    "    elif len(vowels) < 2:\n",
    "        raise IndexError(\"The vowel system needs to contain at least two distinct vowels.\")\n",
    "    \n",
    "    # initialization and sanity check for the list of transparent elements\n",
    "    if transparent is None:\n",
    "        transparent = [\"x\"]\n",
    "    elif [i for i in vowels if i in transparent]:\n",
    "        raise ValueError(\"Lists of harmonizing vowels and transparent elements cannot overlap.\")\n",
    "    \n",
    "    # generate the required number of harmonic strings\n",
    "    strings = []\n",
    "    for i in range(n):\n",
    "        new = choice(vowels)\n",
    "        new += \"\".join([choice(vowels + transparent) for j in range(length - 2)])\n",
    "        if grammatical:\n",
    "            new += new[0]\n",
    "        else:\n",
    "            new += choice([i for i in vowels if i != new[0]])\n",
    "            \n",
    "        strings.append(new)\n",
    "\n",
    "    return strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double harmony\n",
    "\n",
    "When a vowel harmony and a consonant harmony co-occur within the same language. For example, `apapp`, `abbap` and `popooo` are good, while `apabo` and `appoppp` are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vc_harmony_generate(n = 10, length = 10, grammatical = True,\n",
    "                       vowels = None, consonants = None):\n",
    "    \"\"\" Generates a collection words following the rule of vowel-consonant harmony.\n",
    "    \n",
    "    * n (int): number of strings that need to be generated;\n",
    "    * length (int): length of every one of the generated strings;\n",
    "    * grammatical (bool): if set to True, the correctly harmonizing\n",
    "                          forms are generated, and if set to False,\n",
    "                          the disharmonic forms are produced;\n",
    "    * vowels (list): list of vowels among which the agreement\n",
    "                     is established;\n",
    "    * consonants (list): list of consonants among which the agreement\n",
    "                         is established.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialization and sanity check for the list of vowels\n",
    "    if vowels is None:\n",
    "        vowels = [\"a\", \"o\"]\n",
    "    elif len(vowels) < 2:\n",
    "        raise IndexError(\"The vowel system needs to contain at least two distinct vowels.\")\n",
    "        \n",
    "    # initialization and sanity check for the list of consonants\n",
    "    if consonants is None:\n",
    "        consonants = [\"p\", \"b\"]\n",
    "    elif len(consonants) < 2:\n",
    "        raise IndexError(\"The consonant system needs to contain at least two distinct consonants.\")\n",
    "    elif [i for i in vowels if i in consonants] or [i for i in consonants if i in vowels]:\n",
    "        raise ValueError(\"Lists of harmonizing vowels and transparent elements cannot overlap.\")\n",
    "        \n",
    "    # generate the required number of harmonic strings\n",
    "    strings = []\n",
    "    for i in range(n):\n",
    "        v = choice(vowels)\n",
    "        c = choice(consonants)\n",
    "        new = \"\".join([choice([v, c]) for j in range(length)])\n",
    "        \n",
    "        # the ungrammatical forms are created by taking a random index\n",
    "        # and rewriting it to the opposite vowel / consonant\n",
    "        if not grammatical:\n",
    "            ind = choice(range(length))\n",
    "            if new[ind] == c:\n",
    "                new = new[:ind] + choice([i for i in consonants if i != c]) + new[ind + 1:]\n",
    "            else:\n",
    "                new = new[:ind] + choice([i for i in vowels if i != v]) + new[ind + 1:]\n",
    "                \n",
    "        strings.append(new)\n",
    "    \n",
    "    return strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-tier Input-sensitive harmony\n",
    "\n",
    "The trigger for a long-distance assimilation depends on a local context. For example, `e` immediately before `x` prohibits `a` anywhere further after `e` in the string. Then `eaaxaae` and `axaexeeexx` are good, while `exxae` is not.\n",
    "\n",
    "#### 1. Preparing a class to encode input sensitive rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSRule(object):\n",
    "    \"\"\" A generic template for a input-sensititve rule. \n",
    "    \n",
    "    * symbols (tuple): list of tier symbols relevant for the generalization;\n",
    "    * target (str): a target character context of which is important;\n",
    "    * right_context (str): a context in which a target character\n",
    "                           is projected on the tier;\n",
    "    * can_follow (tuple): a list of tier symbols that are allowed after\n",
    "                         the target character is projected.\n",
    "    \"\"\"\n",
    "    def __init__(self, symbols, target, right_context, can_follow):\n",
    "        self.symbols = symbols\n",
    "        self.target = target\n",
    "        self.right_context = right_context\n",
    "        self.can_follow = can_follow\n",
    "\n",
    "    def is_grammatical(self, string):\n",
    "        \"\"\" Checks if the given form follows a rule that is encoded.\n",
    "        \n",
    "        * string (str): a string well-formedness of which needs to be checked.\n",
    "        \"\"\"\n",
    "        \n",
    "        # get rid of all irrelevant symbols (not symbols and contexts)\n",
    "        string = \"\".join([i for i in string if i in list(self.symbols) + [self.right_context]])\n",
    "        \n",
    "        # construct a tier of that strings\n",
    "        tier = \"\"\n",
    "        for i in range(len(string)):\n",
    "            if string[i] in self.symbols:\n",
    "                if string[i] == self.target and i < len(string) - 1 and\\\n",
    "                    string[i + 1] == self.right_context:\n",
    "                    tier += self.target\n",
    "                elif string[i] != self.target:\n",
    "                    tier += string[i]\n",
    "\n",
    "        # check if that tier is well-formed\n",
    "        for t in range(len(tier)):\n",
    "            if tier[t] == self.target and t < len(tier) - 1 and\\\n",
    "                tier[t + 1] not in self.can_follow:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Writing a generator of a sequence grammatical wrt the rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rule_sequence(rule, length = 7, grammatical = True):\n",
    "    \"\"\" This function generates a sequence of symbols (un)grammatical \n",
    "        with respect to the given rule.\n",
    "        \n",
    "    * rule (SSRule): a rule describing an input sensitive dependency;\n",
    "    * length (int): length of the generated sequence;\n",
    "    * grammatical (bool): produces correct form when set to True, and \n",
    "                          makes a mistake when set to False.\n",
    "    \"\"\"\n",
    "    \n",
    "    # the generation of the well-formed sequence is done by a simplistic FSA\n",
    "    sequence = \"\"\n",
    "    state = 0\n",
    "    for i in range(length):\n",
    "        \n",
    "        # State 0: the target was not observed\n",
    "        if state == 0:\n",
    "            sequence += choice(list(rule.symbols) + [rule.right_context])\n",
    "            if sequence[-1] == rule.target:\n",
    "                state = 1\n",
    "                \n",
    "        # State 1: the target was observed\n",
    "        elif state == 1:\n",
    "            sequence += choice(list(rule.symbols) + [rule.right_context])\n",
    "            if sequence[-1] == rule.right_context:\n",
    "                state = 2\n",
    "            elif sequence[-1] != rule.target:\n",
    "                state = 0\n",
    "                \n",
    "        # State 2: the right context was observed\n",
    "        elif state == 2:\n",
    "            sequence += choice(list(rule.can_follow) + [rule.right_context])\n",
    "            if sequence[-1] in rule.can_follow and sequence[-1] != rule.target:\n",
    "                state = 0\n",
    "                \n",
    "    # if the ungrammatical form is needed, a violating sequence is generated\n",
    "    # and inserted into a random position within the sequence\n",
    "    if not grammatical:\n",
    "        violate = rule.target + rule.right_context +\\\n",
    "            choice([i for i in list(rule.symbols) if i not in rule.can_follow])\n",
    "        index_violate = choice(range(length - 3))\n",
    "        sequence = sequence[:index_violate] + violate + sequence[index_violate + 3:]\n",
    "        \n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Intertwine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intertwine(str1, str2, r = (0, 3)):\n",
    "    \"\"\" Intertwines two strings: str1 and str2. At every step, it takes\n",
    "    some characters from one string, and then some characters from another.\n",
    "    oxxooxa\n",
    "    * str1 (str): the first string;\n",
    "    * str2 (str): the second string;\n",
    "    * r (tuple[int, int]): min and max+1 symbols to be taken.\n",
    "    \"\"\"\n",
    "    new_string = \"\"\n",
    "    current = choice([1, 2])\n",
    "    while str1 or str2:\n",
    "        if current == 1:\n",
    "            cut = choice(range(r[0], r[1]))\n",
    "            if len(str1) < cut:\n",
    "                new = str1[:]\n",
    "            else:\n",
    "                new = str1[:cut]\n",
    "            new_string += new\n",
    "            str1 = str1[len(new):]\n",
    "            current = 2\n",
    "        elif current == 2:\n",
    "            cut = choice(range(r[0], r[1]))\n",
    "            if len(str2) < cut:\n",
    "                new = str2[:]\n",
    "            else:\n",
    "                new = str2[:cut]\n",
    "            new_string += new\n",
    "            str2 = str2[len(new):]\n",
    "            current = 1\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Generator for the ITSL harmony\n",
    "A single locally-driven long-distance assimilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itsl_harmony_generate(n = 10, length = 10, grammatical = True,\n",
    "                       rule_1 = None):\n",
    "    \"\"\" Generates a collection words following the given rules of the structure-\n",
    "        Takessensitive dependencies that involve a single tier.\n",
    "    \n",
    "    * n (int): number of strings that need to be generated;\n",
    "    * length (int): length of every one of the generated strings;\n",
    "    * grammatical (bool): if set to True, the correctly harmonizing\n",
    "                          forms are generated, and if set to False,\n",
    "                          the disharmonic forms are produced;\n",
    "    * rule_1 (SSRule): the first rule describing a long-distant structure-\n",
    "                      sensitive dependency.\n",
    "    \"\"\"\n",
    "    \n",
    "    # set the first rule\n",
    "    if rule_1 == None:\n",
    "        rule_1 = SSRule(symbols = (\"o\", \"e\", \"a\"), target = \"o\",\\\n",
    "                        right_context = \"x\", can_follow = (\"a\", \"o\"))\n",
    "    strings = []\n",
    "    for i in range(n):\n",
    "        string = generate_rule_sequence(rule_1, length)\n",
    "        if not grammatical:\n",
    "            string = generate_rule_sequence(rule_1, length, grammatical = False)\n",
    "        strings.append(string)\n",
    "    return strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Generator for the MITSL harmony\n",
    "Two locally-driven long-distance assimilations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imtsl_harmony_generate(n = 10, length = 10, grammatical = True,\n",
    "                       rule_1 = None, rule_2 = None):\n",
    "    \"\"\" Generates a collection words following the given rules of the structure-\n",
    "        Takesinput sensitive dependencies that involve several tiers.\n",
    "    \n",
    "    * n (int): number of strings that need to be generated;\n",
    "    * length (int): length of every one of the generated strings;\n",
    "    * grammatical (bool): if set to True, the correctly harmonizing\n",
    "                          forms are generated, and if set to False,\n",
    "                          the disharmonic forms are produced;\n",
    "    * rule_1 (SSRule): the first rule describing a long-distant input-\n",
    "                      sensitive dependency;\n",
    "    * rule_2 (SSRule): the second rule describing a long-distant input-\n",
    "                      sensitive dependency.\n",
    "    \"\"\"\n",
    "    \n",
    "    # set both rules\n",
    "    if rule_1 == None:\n",
    "        rule_1 = SSRule(symbols = (\"o\", \"e\", \"a\"), target = \"o\",\\\n",
    "                        right_context = \"x\", can_follow = (\"a\", \"o\"))\n",
    "    if rule_2 == None:\n",
    "        rule_2 = SSRule(symbols = (\"b\", \"p\", \"d\"), target = \"b\",\\\n",
    "                        right_context = \"y\", can_follow = (\"b\", \"p\"))\n",
    "    \n",
    "    strings = []\n",
    "    for i in range(n):\n",
    "        # generate two tiers independently, and then intertwine them\n",
    "        # WARNING: the tier alphabets of the two rules cannot overlap\n",
    "        #          (required by both learner and generator)\n",
    "        len_part_1 = length // 2\n",
    "        len_part_2 = length - len_part_1\n",
    "\n",
    "        part_1 = generate_rule_sequence(rule_1, len_part_1)\n",
    "        part_2 = generate_rule_sequence(rule_2, len_part_2)\n",
    "\n",
    "        if not grammatical:\n",
    "            mistake = choice([\"R1\", \"R2\", \"both\"])\n",
    "            if mistake == \"R1\":\n",
    "                part_1 = generate_rule_sequence(rule_1, len_part_1, grammatical = False)\n",
    "            elif mistake == \"R2\":\n",
    "                part_2 = generate_rule_sequence(rule_2, len_part_2, grammatical = False)\n",
    "            else:\n",
    "                part_1 = generate_rule_sequence(rule_1, len_part_1, grammatical = False)\n",
    "                part_2 = generate_rule_sequence(rule_2, len_part_2, grammatical = False)\n",
    "\n",
    "        # intertwining the two generated sequences\n",
    "        new_string = intertwine(part_1, part_2)\n",
    "        strings.append(new_string)\n",
    "        \n",
    "    return strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools: collecting data generators for the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_harmony(kind=\"first-last\", length=range(2, 7), number=1000):\n",
    "    \"\"\"\n",
    "    Generates a harmony based on 3 parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    * kind (str): type of the harmony, choices:\n",
    "        \"first-last\", \"double\", \"assimilation-one\", \"assimilation-two\"\n",
    "    * length (range): a range of lengths of the intended strings\n",
    "    * number (int): a number of strings to be generated\n",
    "    \n",
    "    Outputs:\n",
    "    * list: a collection of strings.\n",
    "    \"\"\"\n",
    "    \n",
    "    # preparing data for easy generation\n",
    "    lennum = {r:number // len(length) for r in length}\n",
    "    hmap = {\"first-last\" : first_last_generate,\n",
    "                   \"double\" : vc_harmony_generate,\n",
    "                   \"assimilation-one\" : itsl_harmony_generate,\n",
    "                   \"assimilation-two\" : imtsl_harmony_generate}\n",
    "    \n",
    "    # generating the data\n",
    "    data = [i for l in lennum for i in hmap[kind](lennum[l], l)]\n",
    "    \n",
    "    # annotate the data with start- and end-markers >> and <<\n",
    "    return list(map(lambda string : \">>\" + string + \"<<\", data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code of the learning algorithm\n",
    "\n",
    "### Generating only well-formed n-grams\n",
    "\n",
    "First, since we generate ngrams automatically, we need to have a checker that nothing like `a<<b`, `a><k`, or `fdh<` is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _well_formed_ngram(ngram):\n",
    "    \"\"\" Checks if ngram is well-formed. \"\"\"\n",
    "    \n",
    "    start, end = [], []\n",
    "    for i in range(len(ngram)):\n",
    "        if ngram[i] == \">\":\n",
    "            start.append(i)\n",
    "        elif ngram[i] == \"<\":\n",
    "            end.append(i)\n",
    "\n",
    "    start_len, end_len = len(start), len(end)\n",
    "    if any([start_len == len(ngram), end_len == len(ngram)]):\n",
    "        return False\n",
    "    \n",
    "    if start_len > 0:\n",
    "        if ngram[0] != \">\":\n",
    "            return False\n",
    "        if start_len > 1:\n",
    "            for i in range(1, start_len):\n",
    "                if start[i] - start[i - 1] != 1:\n",
    "                    return False\n",
    "    \n",
    "    if end_len > 0:\n",
    "        if ngram[-1] != \"<\":\n",
    "            return False\n",
    "        if end_len > 1:\n",
    "            for i in range(1, end_len):\n",
    "                if end[i] - end[i - 1] != 1:\n",
    "                    return False\n",
    "                \n",
    "    # this part is different from the checker from the SigmaPie\n",
    "    # to avoid passing fourgrams such as \"><<<\"\n",
    "    if len(ngram) > 3 and (ngram[1] == \"<\" or ngram[2] == \">\"):\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_ngrams(alphabet, size):\n",
    "    \"\"\" To generate all possible ngrams based on the given alphabet. \"\"\"\n",
    "    \n",
    "    all_of_them = [\"\".join(i) for i in product(alphabet + [\"<\", \">\"], repeat = size)]\n",
    "    return [i for i in all_of_them if _well_formed_ngram(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unattested_ngrams(data, all_ngrams):\n",
    "    \"\"\" Detect list of ngrams that is unattested in the given data. \"\"\"\n",
    "    not_in_data = []\n",
    "    for f in all_ngrams:\n",
    "        found = False\n",
    "        for string in data:\n",
    "            if f in string:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            not_in_data.append(f)\n",
    "            \n",
    "    return not_in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_paths(string, fourgram):\n",
    "    \"\"\" Finds all paths for two given symbols and their contexts. \"\"\"\n",
    "    \n",
    "    paths = {}\n",
    "    \n",
    "    ind_first = [s.start() for s in re.finditer(fourgram[:2], string)]\n",
    "    ind_second = [s.start() for s in re.finditer(fourgram[2:], string)]\n",
    "    \n",
    "    if not (ind_first and ind_second):\n",
    "        return []\n",
    "    \n",
    "    paths = set()\n",
    "    \n",
    "    for f in ind_first:\n",
    "        for s in ind_second:\n",
    "            if f >= s:\n",
    "                continue\n",
    "                \n",
    "            middle = string[f+1:s+1]\n",
    "            in_between = tuple(set(middle[i:i+2] for i in range(len(middle) - 1)))\n",
    "            path = (fourgram[:2], in_between, fourgram[2:])\n",
    "            paths.add(path)\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_paths(data, fourgram):\n",
    "    \"\"\" Collects a list of paths for a particular (unattested) pair of bigrams. \"\"\"\n",
    "    \n",
    "    total_paths = set()\n",
    "    for d in data:\n",
    "        total_paths = total_paths.union(string_paths(d, fourgram))\n",
    "        \n",
    "    return total_paths\n",
    "\n",
    "\n",
    "def find_relevant_paths(data, unattested_ngrams):\n",
    "    \"\"\" Finds all paths for the unattested ngrams. \"\"\"\n",
    "    \n",
    "    relevant_paths = dict()\n",
    "    for un in unattested_ngrams:\n",
    "        relevant_paths[un] = data_paths(data, un)\n",
    "        \n",
    "    return relevant_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def learn_imtsl(data, alphabet, n = 2, context = 2, redacted=False):\n",
    "    \"\"\"\n",
    "    A function that extracts 2local MITSL2 grammars.\n",
    "    \n",
    "    Arguments:\n",
    "    data (list): examples from the target language;\n",
    "    alphabet (list or set): symbols of the language;\n",
    "    n (int): size of the target ngrams (available for 2);\n",
    "    context (int): size of the local context considered (available for 2);\n",
    "    redacted (bool): if set to False, shows grammar as\n",
    "                        {single restriction : corresponding tier alphabet},\n",
    "                     if set to True, shows grammar as\n",
    "                        {tier alphabet : corresponding restrictions}.\n",
    "    \n",
    "    Returns:\n",
    "    dict: keys are tier alphabets, values are tier grammars.\n",
    "    \"\"\"\n",
    "    \n",
    "    if n != 2 or context != 2:\n",
    "        raise NotImplementedError(\"This algorithm does not support such values yet.\")\n",
    "        \n",
    "    # collect a list of unattested ngrams (n * context = 2 * 2 = 4)\n",
    "    unattested = unattested_ngrams(data, generate_all_ngrams(alphabet, 4))\n",
    "    \n",
    "    # build a look-up table with the relevant paths\n",
    "    relevant_paths = find_relevant_paths(data, unattested)\n",
    "    \n",
    "    # initialize the grammar and the maximum tier\n",
    "    max_tier_guess = generate_all_ngrams(alphabet, context)\n",
    "    grammar = dict()\n",
    "    \n",
    "    for un in unattested:\n",
    "        \n",
    "        # collect the collection of paths for the unattested bigrams\n",
    "        local_tier = [un[:2], un[2:]]\n",
    "        local_relevant = [(i[0], set(i[1]), i[2]) for i in relevant_paths[un]]\n",
    "        \n",
    "        for ss in max_tier_guess:\n",
    "            \n",
    "            # members of the unattested bigram must be on the tier\n",
    "            if ss in [un[:2], un[2:]]:\n",
    "                continue\n",
    "            \n",
    "            # if can remove from any path, the symbol is not a tier symbol\n",
    "            contain_ss = [i for i in local_relevant if ss in i[1]]\n",
    "            added = False\n",
    "            for pth in contain_ss:\n",
    "                no_ss_in_path = (pth[0], set(i for i in pth[1] if i != ss), pth[2])\n",
    "                if no_ss_in_path not in local_relevant:\n",
    "                    local_tier.append(ss)\n",
    "                    added = True\n",
    "                    break\n",
    "                if added:\n",
    "                    continue\n",
    "        \n",
    "        # assemble the grammar\n",
    "        grammar[(un[:2], un[2:])] = local_tier[:]\n",
    "        \n",
    "    if not redacted:\n",
    "        return grammar\n",
    "    \n",
    "    # if redacted=True, reassemble the grammar\n",
    "    new_grammar = dict()\n",
    "    for pair in grammar:\n",
    "        if tuple(grammar[pair]) not in new_grammar:\n",
    "            new_grammar[tuple(grammar[pair])] = [pair]\n",
    "        else:\n",
    "            new_grammar[tuple(grammar[pair])].append([pair])\n",
    "    \n",
    "    del grammar\n",
    "    return new_grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_harmony = generate_harmony(\"first-last\", range(2, 8), number = 10000)\n",
    "fl_sigma = [\"a\", \"x\", \"o\"]\n",
    "\n",
    "fl_grammar = learn_imtsl(fl_harmony, fl_sigma)\n",
    "# pprint(fl_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_harmony = generate_harmony(\"double\", range(2, 8), number = 10000)\n",
    "double_sigma = [\"a\", \"o\", \"b\", \"p\"]\n",
    "\n",
    "double_grammar = learn_imtsl(double_harmony, double_sigma)\n",
    "# pprint(double_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ox', 'oe') : ['ox', 'oe', 'ao', 'ae', 'ax', 'oa', 'ea', 'eo', 'ex', 'xa', 'xo']\n",
      "('ox', 'ea') : ['ox', 'ea', 'ao', 'ae', 'ax', 'oa', 'oe', 'ee', 'xa', 'xo', 'xe', 'xx']\n",
      "('ox', 'eo') : ['ox', 'eo', 'aa', 'ao', 'ae', 'ax', 'oa', 'oe', 'xa', 'xo', 'xe']\n",
      "('ox', 'ee') : ['ox', 'ee', 'ao', 'ae', 'ax', 'oa', 'oe', 'eo', 'xa', 'xo', 'xe']\n",
      "('ox', 'ex') : ['ox', 'ex', 'ao', 'ae', 'ax', 'oa', 'oe', 'xa', 'xo', 'xe', 'xx']\n",
      "('ox', 'e<') : ['ox', 'e<', 'aa', 'ao', 'ae', 'ax', 'oa', 'oo', 'oe', 'ea', 'eo', 'ee', 'ex', 'xa', 'xo', 'xe', 'xx']\n",
      "('ox', 'xe') : ['ox', 'xe', 'ae', 'ax', 'oa', 'ex', 'xa', 'xo', 'xx']\n"
     ]
    }
   ],
   "source": [
    "assim_one = generate_harmony(\"assimilation-one\", range(2, 8), number = 10000)\n",
    "assim_one_sigma = [\"a\", \"o\", \"e\", \"x\"]\n",
    "\n",
    "assim_one_grammar = learn_imtsl(assim_one, assim_one_sigma)\n",
    "# pprint(assim_one_grammar)\n",
    "\n",
    "for i in assim_one_grammar:\n",
    "    if i[0] == 'ox':\n",
    "        print(i, \":\", assim_one_grammar[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ox', 'aa') : ['ox', 'aa']\n",
      "('ox', 'ao') : ['ox', 'ao']\n",
      "('ox', 'ae') : ['ox', 'ae']\n",
      "('ox', 'ax') : ['ox', 'ax']\n",
      "('ox', 'oa') : ['ox', 'oa']\n",
      "('ox', 'oo') : ['ox', 'oo']\n",
      "('ox', 'oe') : ['ox', 'oe']\n",
      "('ox', 'ox') : ['ox', 'ox']\n",
      "('ox', 'ea') : ['ox', 'ea']\n",
      "('ox', 'eo') : ['ox', 'eo']\n",
      "('ox', 'ee') : ['ox', 'ee']\n",
      "('ox', 'ex') : ['ox', 'ex']\n",
      "('ox', 'eb') : ['ox', 'eb']\n",
      "('ox', 'ep') : ['ox', 'ep']\n",
      "('ox', 'ed') : ['ox', 'ed']\n",
      "('ox', 'ey') : ['ox', 'ey']\n",
      "('ox', 'e<') : ['ox', 'e<']\n",
      "('ox', 'xa') : ['ox', 'xa']\n",
      "('ox', 'xo') : ['ox', 'xo']\n",
      "('ox', 'xe') : ['ox', 'xe']\n",
      "('ox', 'xx') : ['ox', 'xx']\n",
      "('ox', 'bo') : ['ox', 'bo', 'xb', 'bb']\n",
      "('ox', 'be') : ['ox', 'be']\n",
      "('ox', 'pe') : ['ox', 'pe']\n",
      "('ox', 'px') : ['ox', 'px', 'xd', 'xy', 'dd', 'dy', 'yp']\n",
      "('ox', 'da') : ['ox', 'da', 'xp', 'pd']\n",
      "('ox', 'de') : ['ox', 'de']\n",
      "('ox', 'ye') : ['ox', 'ye']\n",
      "('by', 'ad') : ['by', 'ad']\n",
      "('by', 'od') : ['by', 'od']\n",
      "('by', 'ed') : ['by', 'ed', 'pe', 'yp']\n",
      "('by', 'xd') : ['by', 'xd', 'ex', 'pe', 'yp']\n",
      "('by', 'bd') : ['by', 'bd']\n",
      "('by', 'py') : ['by', 'py']\n",
      "('by', 'da') : ['by', 'da']\n",
      "('by', 'do') : ['by', 'do', 'ep', 'pd', 'ye']\n",
      "('by', 'de') : ['by', 'de', 'pd', 'yp']\n",
      "('by', 'dx') : ['by', 'dx', 'ed', 'pe', 'pd', 'yp']\n",
      "('by', 'db') : ['by', 'db']\n",
      "('by', 'dp') : ['by', 'dp']\n",
      "('by', 'dd') : ['by', 'dd']\n",
      "('by', 'dy') : ['by', 'dy']\n",
      "('by', 'd<') : ['by', 'd<', 'ap', 'op', 'ex', 'xp', 'xd', 'pe', 'pd', 'ya', 'yo', 'yx', 'yp']\n",
      "('by', 'yd') : ['by', 'yd']\n"
     ]
    }
   ],
   "source": [
    "assim_two = generate_harmony(\"assimilation-two\", range(2, 8), number = 10000)\n",
    "assim_two_sigma = [\"a\", \"o\", \"e\", \"x\", \"b\", \"p\", \"d\", \"y\"]\n",
    "\n",
    "assim_two_grammar = learn_imtsl(assim_two, assim_two_sigma)\n",
    "# pprint(assim_two_grammar)\n",
    "\n",
    "for i in assim_two_grammar:\n",
    "    if i[0] in {'ox', 'by'}:\n",
    "        print(i, \":\", assim_two_grammar[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
